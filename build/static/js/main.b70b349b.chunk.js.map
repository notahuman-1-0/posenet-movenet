{"version":3,"sources":["App.js","reportWebVitals.js","index.js"],"names":["detector","startInferenceTime","rafId","canvasFullScreen","ctxFullScreen","model","modelType","VIDEO_CONSTRAINTS","facingMode","deviceId","frameRate","max","ideal","width","isMobile","height","MOVENET_CONFIG","numInferences","inferenceTimeSum","lastPanelUpdate","App","useState","cameraReady","setCameraReady","displayFps","setDisplayFps","webcamRef","useRef","useEffect","_loadPoseNet","then","a","window","cancelAnimationFrame","dispose","createDetector","renderPrediction","poseDetection","MoveNet","SINGLEPOSE_LIGHTNING","renderResult","requestAnimationFrame","video","current","readyState","beginEstimatePosesStats","estimatePoses","maxPoses","flipHorizontal","poses","endEstimatePosesStats","drawCtxFullScreen","length","drawResultsFullScreen","performance","Date","now","endInferenceTime","averageInferenceTime","document","getElementById","getContext","videoWidth","videoHeight","fillRect","translate","scale","drawImage","pose","drawResult","keypoints","drawKeypoints","drawSkeleton","keypointInd","getKeypointIndexBySide","fillStyle","strokeStyle","lineWidth","middle","i","drawKeypoint","left","right","keypoint","score","circle","Path2D","arc","x","y","Math","PI","fill","stroke","getAdjacentPairs","forEach","j","kp1","kp2","score1","score2","scoreThreshold","beginPath","moveTo","lineTo","className","style","visibility","ref","audio","videoConstraints","onUserMediaError","console","log","onUserMedia","id","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode"],"mappings":"yQA6BIA,EACAC,EAIAC,EACAC,EACAC,EACAC,EACAC,E,yJAzBEC,EAAoB,CACtBC,WAAY,OACZC,SAAU,GACVC,UAAW,CAACC,IAAK,GAAIC,MAAO,IAC5BC,MAAOC,WAAW,IAAM,KACxBC,OAAQD,WAAW,IAAM,KAEvBE,EACQ,EADRA,EAGc,GAQhBC,EAAgB,EAChBC,EAAmB,EACnBC,EAAkB,EAwMPC,MAjMf,WAAgB,IAAD,EAC2BC,oBAAS,GADpC,mBACJC,EADI,KACSC,EADT,OAEyBF,mBAAS,GAFlC,mBAEJG,EAFI,KAEQC,EAFR,KAGLC,EAAYC,iBAAO,IAEzBC,qBAAU,WACNC,IAAeC,SAGhB,IAEH,IAAMD,EAAY,uCAAG,sBAAAE,EAAA,6DACb7B,IACA8B,OAAOC,qBAAqB/B,GAC5BF,EAASkC,WAHI,SAMAC,IANA,cAMjBnC,EANiB,gBAOXoC,IAPW,2CAAH,qDAUZD,EAAc,uCAAG,sBAAAJ,EAAA,6DACnB1B,EAAQgC,IAA8BC,QACtChC,EAAY+B,IAAsB/B,UAAUiC,qBAFzB,SAGNF,IAA6BhC,EAAO,CAACC,UAAWA,IAH1C,mFAAH,qDAMd8B,EAAgB,uCAAG,sBAAAL,EAAA,sEACfS,IADe,OAErBtC,EAAQuC,sBAAsBL,GAFT,2CAAH,qDAKhBI,EAAY,uCAAG,8BAAAT,EAAA,yDACXW,EAAQhB,EAAUiB,SAAWjB,EAAUiB,QAAV,MAE9BrB,GAAgBoB,EAHJ,sDAObA,EAAME,WAAa,GAPN,wDAWjBC,IAXiB,SAYG7C,EAAS8C,cAAcJ,EAAO,CAC9CK,SAAU/B,EACVgC,gBAAgB,IAdH,OAYXC,EAZW,OAgBjBC,IACAC,EAAkBT,GAEdO,EAAMG,OAAS,GACfC,EAAsBJ,GApBT,4CAAH,qDAwBZJ,EAA0B,WAC5B5C,GAAsBqD,aAAeC,MAAMC,OAGzCN,EAAwB,WAC1B,IAAMO,GAAoBH,aAAeC,MAAMC,MAC/CtC,GAAoBuC,EAAmBxD,IACrCgB,EAGF,GAAIwC,EAAmBtC,GAFS,IAEmC,CAC/D,IAAMuC,EAAuBxC,EAAmBD,EAChDC,EAAmB,EACnBD,EAAgB,EAChBQ,EAAc,IAASiC,EAAsB,KAC7CvC,EAAkBsC,IAIpBN,EAAoB,SAACT,GACvBvC,EAAmBwD,SAASC,eAAe,sBAC3CxD,EAAgBD,EAAiB0D,WAAW,MAE5C,IAAMC,EAAapB,EAAMoB,WACnBC,EAAcrB,EAAMqB,YAE1BrB,EAAM7B,MAAQiD,EACdpB,EAAM3B,OAASgD,EAEf5D,EAAiBU,MAAQiD,EACzB3D,EAAiBY,OAASgD,EAC1B3D,EAAc4D,SAAS,EAAG,EAAGF,EAAYC,GAEzC3D,EAAc6D,UAAUvB,EAAMoB,WAAY,GAC1C1D,EAAc8D,OAAO,EAAG,GACxB9D,EAAc+D,UAAUzB,EAAO,EAAG,EAAGoB,EAAYC,IAG/CV,EAAwB,SAACJ,GAAW,IAAD,gBAClBA,GADkB,IACrC,2BAA0B,CAAC,IAAhBmB,EAAe,QACtBC,EAAWD,IAFsB,gCAMnCC,EAAa,SAACD,GACM,MAAlBA,EAAKE,YACLC,EAAcH,EAAKE,WACnBE,EAAaJ,EAAKE,aAIpBC,EAAgB,SAACD,GACnB,IAAMG,EAAcpC,IAAmBqC,uBAAuBrE,GAC9DD,EAAcuE,UAAY,QAC1BvE,EAAcwE,YAAc,QAC5BxE,EAAcyE,UA7HK,EAyHc,oBAMjBJ,EAAYK,QANK,IAMjC,2BAAoC,CAAC,IAA1BC,EAAyB,QAChCC,EAAaV,EAAUS,KAPM,8BAUjC3E,EAAcuE,UAAY,QAVO,oBAYjBF,EAAYQ,MAZK,IAYjC,2BAAkC,CAAC,IAAxBF,EAAuB,QAC9BC,EAAaV,EAAUS,KAbM,8BAgBjC3E,EAAcuE,UAAY,SAhBO,oBAkBjBF,EAAYS,OAlBK,IAkBjC,2BAAmC,CAAC,IAAzBH,EAAwB,QAC/BC,EAAaV,EAAUS,KAnBM,gCAuB/BC,EAAe,SAACG,GAKlB,IAHgC,MAAlBA,EAASC,MAAgBD,EAASC,MAAQ,KACjCpE,GAAiC,GAE3B,CACzB,IAAMqE,EAAS,IAAIC,OACnBD,EAAOE,IAAIJ,EAASK,EAAGL,EAASM,EAtJrB,EAsJwC,EAAG,EAAIC,KAAKC,IAC/DvF,EAAcwF,KAAKP,GACnBjF,EAAcyF,OAAOR,KAIvBb,EAAe,SAACF,GAClBlE,EAAcuE,UAAY,QAC1BvE,EAAcwE,YAAc,QAC5BxE,EAAcyE,UAhKK,EAiKnBxC,IAAmByD,iBAAiBzF,GAAO0F,SAAQ,YAAa,IAAD,mBAAVhB,EAAU,KAAPiB,EAAO,KACrDC,EAAM3B,EAAUS,GAChBmB,EAAM5B,EAAU0B,GAEhBG,EAAsB,MAAbF,EAAIb,MAAgBa,EAAIb,MAAQ,EACzCgB,EAAsB,MAAbF,EAAId,MAAgBc,EAAId,MAAQ,EACzCiB,EAAiBrF,GAAiC,EAEpDmF,GAAUE,GAAkBD,GAAUC,IACtCjG,EAAckG,YACdlG,EAAcmG,OAAON,EAAIT,EAAGS,EAAIR,GAChCrF,EAAcoG,OAAON,EAAIV,EAAGU,EAAIT,GAChCrF,EAAcyF,cAc1B,OACI,yBAASY,UAAU,oEAAnB,SACI,sBAAKA,UAAU,cAAf,UACI,cAAC,IAAD,CACIA,UAAU,iBACVC,MAAO,CAACC,WAAY,UACpBC,IAAKlF,EACLmF,OAAO,EACP9F,OAAQD,WAAW,IAAM,IACzBD,MAAOC,WAAW,IAAM,KACxBgG,iBAAkBvG,EAClBwG,iBApBS,WACrBC,QAAQC,IAAI,qBAoBAC,YAjBI,WAChBF,QAAQC,IAAI,kBACZ1F,GAAe,MAgBP,wBAAQkF,UAAU,WAAWU,GAAG,uBAChC,wBAAOV,UAAU,aAAjB,kBAAoCjF,WCvNrC4F,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,8BAAqBxF,MAAK,YAAkD,IAA/CyF,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCDdO,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFnE,SAASC,eAAe,SAM1BwD,M","file":"static/js/main.b70b349b.chunk.js","sourcesContent":["import './App.css';\n// eslint-disable-next-line\nimport * as tfJsCore from '@tensorflow/tfjs-core';\n// eslint-disable-next-line\nimport * as tfJsConverter from '@tensorflow/tfjs-converter';\n// eslint-disable-next-line\nimport * as tfJsBackendWebgl from '@tensorflow/tfjs-backend-webgl';\n\nimport {useEffect, useRef, useState} from \"react\";\nimport Webcam from \"react-webcam\";\nimport {isMobile} from 'react-device-detect';\nimport * as poseDetection from '@tensorflow-models/pose-detection';\n\nconst VIDEO_CONSTRAINTS = {\n    facingMode: \"user\",\n    deviceId: \"\",\n    frameRate: {max: 60, ideal: 30},\n    width: isMobile ? 360 : 1280,\n    height: isMobile ? 270 : 720\n};\nconst MOVENET_CONFIG = {\n    maxPoses: 1,\n    type: 'lightning',\n    scoreThreshold: 0.3\n};\n\nconst DEFAULT_LINE_WIDTH = 2;\nconst DEFAULT_RADIUS = 4;\n\nlet detector;\nlet startInferenceTime,\n    numInferences = 0;\nlet inferenceTimeSum = 0,\n    lastPanelUpdate = 0;\nlet rafId;\nlet canvasFullScreen;\nlet ctxFullScreen;\nlet model;\nlet modelType;\n\nfunction App() {\n    const [cameraReady, setCameraReady] = useState(false);\n    const [displayFps, setDisplayFps] = useState(0);\n    const webcamRef = useRef({});\n\n    useEffect(() => {\n        _loadPoseNet().then();\n\n        // eslint-disable-next-line\n    }, []);\n\n    const _loadPoseNet = async () => {\n        if (rafId) {\n            window.cancelAnimationFrame(rafId);\n            detector.dispose();\n        }\n\n        detector = await createDetector();\n        await renderPrediction();\n    }\n\n    const createDetector = async () => {\n        model = poseDetection.SupportedModels.MoveNet;\n        modelType = poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING; //or SINGLEPOSE_THUNDER\n        return await poseDetection.createDetector(model, {modelType: modelType});\n    }\n\n    const renderPrediction = async () => {\n        await renderResult();\n        rafId = requestAnimationFrame(renderPrediction);\n    }\n\n    const renderResult = async () => {\n        const video = webcamRef.current && webcamRef.current['video'];\n\n        if (!cameraReady && !video) {\n            return;\n        }\n\n        if (video.readyState < 2) {\n            return;\n        }\n\n        beginEstimatePosesStats();\n        const poses = await detector.estimatePoses(video, {\n            maxPoses: MOVENET_CONFIG.maxPoses, //When maxPoses = 1, a single pose is detected\n            flipHorizontal: false\n        });\n        endEstimatePosesStats();\n        drawCtxFullScreen(video);\n\n        if (poses.length > 0) {\n            drawResultsFullScreen(poses);\n        }\n    }\n\n    const beginEstimatePosesStats = () => {\n        startInferenceTime = (performance || Date).now();\n    }\n\n    const endEstimatePosesStats = () => {\n        const endInferenceTime = (performance || Date).now();\n        inferenceTimeSum += endInferenceTime - startInferenceTime;\n        ++numInferences;\n        const panelUpdateMilliseconds = 1000;\n\n        if (endInferenceTime - lastPanelUpdate >= panelUpdateMilliseconds) {\n            const averageInferenceTime = inferenceTimeSum / numInferences;\n            inferenceTimeSum = 0;\n            numInferences = 0;\n            setDisplayFps(1000.0 / averageInferenceTime, 120);\n            lastPanelUpdate = endInferenceTime;\n        }\n    }\n\n    const drawCtxFullScreen = (video) => {\n        canvasFullScreen = document.getElementById('output-full-screen');\n        ctxFullScreen = canvasFullScreen.getContext('2d');\n\n        const videoWidth = video.videoWidth;\n        const videoHeight = video.videoHeight;\n\n        video.width = videoWidth;\n        video.height = videoHeight;\n\n        canvasFullScreen.width = videoWidth;\n        canvasFullScreen.height = videoHeight;\n        ctxFullScreen.fillRect(0, 0, videoWidth, videoHeight);\n\n        ctxFullScreen.translate(video.videoWidth, 0);\n        ctxFullScreen.scale(-1, 1);\n        ctxFullScreen.drawImage(video, 0, 0, videoWidth, videoHeight);\n    }\n\n    const drawResultsFullScreen = (poses) => {\n        for (const pose of poses) {\n            drawResult(pose);\n        }\n    }\n\n    const drawResult = (pose) => {\n        if (pose.keypoints != null) {\n            drawKeypoints(pose.keypoints);\n            drawSkeleton(pose.keypoints);\n        }\n    }\n\n    const drawKeypoints = (keypoints) => {\n        const keypointInd = poseDetection.util.getKeypointIndexBySide(model);\n        ctxFullScreen.fillStyle = 'White';\n        ctxFullScreen.strokeStyle = 'White';\n        ctxFullScreen.lineWidth = DEFAULT_LINE_WIDTH;\n\n        for (const i of keypointInd.middle) {\n            drawKeypoint(keypoints[i]);\n        }\n\n        ctxFullScreen.fillStyle = 'Green';\n\n        for (const i of keypointInd.left) {\n            drawKeypoint(keypoints[i]);\n        }\n\n        ctxFullScreen.fillStyle = 'Orange';\n\n        for (const i of keypointInd.right) {\n            drawKeypoint(keypoints[i]);\n        }\n    }\n\n    const drawKeypoint = (keypoint) => {\n        // If score is null, just show the keypoint.\n        const score = keypoint.score != null ? keypoint.score : 1;\n        const scoreThreshold = MOVENET_CONFIG.scoreThreshold || 0;\n\n        if (score >= scoreThreshold) {\n            const circle = new Path2D();\n            circle.arc(keypoint.x, keypoint.y, DEFAULT_RADIUS, 0, 2 * Math.PI);\n            ctxFullScreen.fill(circle);\n            ctxFullScreen.stroke(circle);\n        }\n    }\n\n    const drawSkeleton = (keypoints) => {\n        ctxFullScreen.fillStyle = 'White';\n        ctxFullScreen.strokeStyle = 'White';\n        ctxFullScreen.lineWidth = DEFAULT_LINE_WIDTH;\n        poseDetection.util.getAdjacentPairs(model).forEach(([i, j]) => {\n            const kp1 = keypoints[i];\n            const kp2 = keypoints[j]; // If score is null, just show the keypoint.\n\n            const score1 = kp1.score != null ? kp1.score : 1;\n            const score2 = kp2.score != null ? kp2.score : 1;\n            const scoreThreshold = MOVENET_CONFIG.scoreThreshold || 0;\n\n            if (score1 >= scoreThreshold && score2 >= scoreThreshold) {\n                ctxFullScreen.beginPath();\n                ctxFullScreen.moveTo(kp1.x, kp1.y);\n                ctxFullScreen.lineTo(kp2.x, kp2.y);\n                ctxFullScreen.stroke();\n            }\n        });\n    }\n\n    const onUserMediaError = () => {\n        console.log('ERROR in Camera!');\n    };\n\n    const onUserMedia = () => {\n        console.log('Camera loaded!');\n        setCameraReady(true);\n    };\n\n    return (\n        <section className=\"App h-screen w-full flex justify-center items-center bg-green-500\">\n            <div className=\"bg-gray-800\">\n                <Webcam\n                    className=\"filter blur-lg\"\n                    style={{visibility: \"hidden\"}}\n                    ref={webcamRef}\n                    audio={false}\n                    height={isMobile ? 270 : 720}\n                    width={isMobile ? 360 : 1280}\n                    videoConstraints={VIDEO_CONSTRAINTS}\n                    onUserMediaError={onUserMediaError}\n                    onUserMedia={onUserMedia}/>\n                <canvas className=\"absolute\" id=\"output-full-screen\"/>\n                <label className=\"text-white\">FPS: {displayFps}</label>\n            </div>\n        </section>\n    );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}